# Project Overview

This project is organized into four main files, each focusing on key machine learning and NLP concepts.

---

## 📁 Files to Analyze (in Order)
1. **Word2vec** – Word embeddings, CBOW, and Skip-gram
2. **attn** – Self-attention and multi-head attention
3. **mlp** – Multi-layer perceptrons (MLPs)
4. **gpt** – Full GPT-style language model integration

---

## 📚 Topics to Cover
1. **Vectors**
2. **Calculus**
3. **CBOW**
4. **Skip-gram**
5. **Self-attention**
6. **Multi-head attention**
7. **Multi-layer perceptron**
8. **Probabilities**
