# Project Overview

This project is organized into four main files, each focusing on key machine learning and NLP concepts.

---

## ğŸ“ Files to Analyze (in Order)
1. **Word2vec** â€“ Word embeddings, CBOW, and Skip-gram
2. **attn** â€“ Self-attention and multi-head attention
3. **mlp** â€“ Multi-layer perceptrons (MLPs)
4. **gpt** â€“ Full GPT-style language model integration

---

## ğŸ“š Topics to Cover
1. **Vectors**
2. **Calculus**
3. **CBOW**
4. **Skip-gram**
5. **Self-attention**
6. **Multi-head attention**
7. **Multi-layer perceptron**
8. **Probabilities**
